---
title: "Prostate Cancer Case Study"
output:
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '3'
    toc_float:
      collapsed: yes
  html_notebook:
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: yes
---

## Introduction

This notebook will demonstrate how to write code
for survival analysis. Readers should already know the basics of R. 
Calling functions, loading data, and manipulating
dataframes should be familiar. It'll also
be helpful to have taken an introductory statistics course
and understand concepts like linear regression,
hypothesis testing, p-values, and confidence intervals.

Today we'll be examining a dataset from Green and Byar
(1980, Bulletin Cancer, Paris, 67, 477-488) with 502
prostate cancer patients from a randomized clinical
trial for estrogen therapy. The dataset includes information 
on cancer stage, treatment, age, weight, and 
additional clinical measurements.

First, we load the necessary packages.

```{r echo=TRUE}
library(rms)
require(rpart)
library(dplyr)
library(ggplot2)
library(mice)
library(stringr)
library(tidyr)
```

`rms` provides tools for regression modeling. `dplyr` helps
us easily manipulate dataframes. `ggplot2` will allow us
to visualize our data. `rpart`, `mice`, and `tidyr` help us deal
with missing data. `stringr` makes it easier to work
with strings. 

Next, we load the `prostate` dataset, included in the `rms` packages.

```{r}
getHdata(prostate)
head(prostate)
```

Before we begin our analysis, we should have already prespecified what
questions we want to answer. Designing questions to investigate
beforehand helps us plan the statistical analysis, mitigating bias.
If we're conducting an exploratory analysis or data mining investigation,
we should remember this as we weigh any significant findings. 

In this tutorial we'll focus on the following questions:

1. What effect does treatment have on survival?
2. How does age affect survival?
2. Does bone metastases effect treatment efficacy?
3. What factors are most prognostic of survival?

## Data Preparation

Before modeling it's important
to conduct Exploratory Data Analysis (EDA) to become familiar
with data nuances. This often includes looking
at the distribution of each variable and understanding patterns 
between variables. 

### Data Cleaning

There's a few adjustments to the prostate data we'll need to
make. `status` is encoding with the cause of death.
Let's ignore cause of death and encode status so 1 means death
and 0 means censored.

```{r}
prostate <- prostate %>%
  mutate(status = case_when(
    str_detect(status, "dead") ~ 1,
    str_detect(status, "alive") ~ 0
  ))
head(prostate)
```

This dataset was already cleaned and encoding for teaching uses, so our job
here is done. Be careful though; in a real analysis the data probably won't
be this clean. Pay special attention to categorical variables that need
to be encoded as factors. Check what the reference level is for each factor
before moving onto modeling.

The reference level is the "category" that is used to compare all other categories
against. For example, `rx` has 4 categories:
```{r}
levels(prostate$rx)
```

"placebo" is the first level, meaning it's the reference level. This makes sense,
as we'll want to compare estrogen with the placebo. Failure to make sure
all appropriate variables are properly encoded factors can cause errors in
the analysis.

### Missing Data

EDA often informs us about missing data. 
Understanding and addressing missing data is crucial for
modeling success. Excluding patients due to missing data can
decrease sample size reducing power. It also risks biasing
the analysis if missing values are missing for a systematic reason.

For example, say blood pressure is only measured after surgery.
If some patients die during surgery and they'll be missing
post-op blood pressure measurements.Excluding these patients from 
analysis will cause selection bias as we are only analyzing patients 
that managed to survive surgery.

There are three types of missing data:

* Missing at Completely Random (MCAR) - Data is missing due
to errors like a dropped test tube in the hospital's lab.
Because these data are missing due to random chance, it's
impossible to predict their missingness.
* Missing at Random (MAR) - Data is not missing completely at 
random, but the probability of data being missing depends on the
other measured variables.
* Informative Missing (MI) - Missing data is dependent
on some piece of information we haven't measured. This is the
most difficult type of missing data to account for, and special
modeling techniques are often needed. If your data is MI, go
find a statistician.

It's important to characterize what data is missing
and why. It's best to consult with a domain expert
to understand why data is missing. Make sure to describe missing
data patterns when reporting results so readers can understand
limitations of your analysis.

To help uncover these patterns, `rms` and `mice` provide functions
to identify missing data patterns. First let's see which variables
are missing values.


```{r}
md.pattern(prostate)
```

This tells us that 475 patients have complete data (blue indicates no missing values).
11 patients are missing `sg` measurements (red indicates missingness) and so on.
No patients are missing multiple measurements.


`naclus`  and `naplot` summarizes info about how often each variable 
is missing.`na per var` tells `naplot()` to only show how many
missing values per variable. See the `naplot()` documentation for
more info.

```{r}
na.patterns <- naclus(prostate)
naplot(na.patterns)
```

From these plots, we can see `age`, `wt`, `sz`, `ekg`, and `sg` all have missing values.
We can also use decision trees to identify which types of patients were likely
to have `sg` missing. This builds a model to predict which patients will be missing
`sg` based on other patient characteristics. Note the formula syntax in the `rpart`
call.

```{r}
who.na <- rpart(is.na(sg) ~ stage + rx + pf + hx + sbp + dbp + 
                  hg + ap + bm, data = prostate, minbucket=15)
plot(who.na, margin = .1)
text(who.na)
```

It looks like `dbp` and `hg` are predictors of `sg` missingness.
Now would be a good time to consult the clinician to ask why `dbp` 
and `hg` are predictive of missing `sg`. 

It's also good to know which variables are missing simultaneously from
patients. The code below demonstrates this function

```{r}
plot(na.patterns)
```

In this case, so few data is missing that the plot looks empty.
If more data was missing, the plot would show a clustering map that
groups variables missing together most often. This plot can help us identify
which variables may dependent on each other (they may be measured at the same time). 
The empty plot indicates there isn't a systematic issue with missing data. To see
more examples with `plot(na.patterns)`, refer to Frank Harrell's 
[Regression Modeling Strategies (RMS)](http://hbiostat.org/doc/rms.pdf) 
Chapter 12.4 for another case study on missing data. You'll see a proper
clustering example.

After we've characterized missing data patterns, it's time to decide
how to tackle our missing data. 

Harrell proposes a general rule of thumb when deciding how to approach missing data:

| Amount Missing                         | What to do                                 |
|----------------------------------------|--------------------------------------------|
| Less than 3%                           | Median Imputation or case-wise deletion    |
| More than 3%                           | MICE with max(5, 100x) imputations         |
| Multiple predictors frequently missing | Sensitivity analysis with more imputations |

Median imputation is where we compute a median value for a variable, and replace
all missing values with this median. Case-wise deletion means exlcuding patients
with any missing values from analysis. If a sensitivity analysis is needed, 
consult a statistician.

Using MICE requires two key decision:

1. Is the MAR assumption plausible? If we can't assume MAR,
time to find a statistician. 

2. Assuming MAR, how will we model our missing data? What variables
should we use as information in our model?

If a sensitivity analysis is needed, consult a statistician.

1\) ultimately comes down to whether we think
there are unmeasured variables that **significantly** correlate with
missingness. Unmeasured variables that are only slightly correlated with 
missingness should not prevent us from assuming MAR. We can also gather
additional information outside of our survival analysis parameters of interest
to build the imputation model. Although we may not be interested in analyzing
the effect of hospital location on survival, we can still include this variable
in our imputation model if it will help predict missingness. See section
6.2 in Stef van Burren's 
[Flexible Imputation of Missing Data (FIMD)](https://stefvanbuuren.name/fimd/sec-whenignorable.html)
for more details on deciding about MAR assumptions.

For 2), we can model missing data using MICE (Multiple Imputation 
By Chained Equation). We tell MICE which variables
affect missingness, and then MICE uses these variables to
generate a dataset with predicted values for missing data. Each predicted
value has a random error component. We generate several datasets with
different predicted values, analyze each dataset separate, and then
average our results across datasets. Using multiple datasets
retains the uncertainty from data being missing in the first place.

To use MICE, we need to specify our imputation model: which variables are we
going to include, what imputation method are we going to use,
and what order will we impute variables. MICE chooses chooses
robust defaults for all of these decisions. Predictive
Mean Matching `pmm` is the default imputation method. 
When we pass `mice` a dataframe it will use all variables
in the dataframe for the imputation model. If there are more than
20-30 variables in the imputation model, MICE will slow down and
may not run. In this case, we can tell MICE to only use some
variables. Make sure to include all variables
that you'll be analyzing (anything that is going in the Cox regression)
and any variables that you suspect play a role in missingness.

See van Burren 
[section 6.3](https://stefvanbuuren.name/fimd/sec-modelform.html)
for how to set which variables to include and more info
on choosing variables.

Now let's actually impute our missing data with MICE!

```{r echo=T, eval=FALSE}
impute_transform <- prostate %>%
  select(-patno, sdate) %>%
  mice(m = 5, method = 'pmm')
impute_fit <- fit.mult.impute(Surv(dtime, status) ~ rx + stage + rcs(age, 3), 
                              cph, impute_transform, data = prostate)
```

This code does two things. First, we use `mice()` to impute our missing data.
The first argument `prostate` should be the dataframe 
with missing values and any extra info about these missing values. Don't include
useless columns like PatientNumber. This will only slow down or worsen the imputation.
Notice we removed `patno` and `sdate` before using `mice()`.
process. `m` is the number of imputations to generate. `method = 'pmm'` tells MICE
which imputation algorithm to use.

After mice has run, `fit.mult.impute()` will build a model for each
imputed dataset and average the models for us. The first argument is
the regression formula you desire - don't worry about the formula above,
this will be explained in more detail later. `cph` is the type of regression
model you want to use. `impute_transform` is the imputation object `mice`
created for us. 

Missing data can be a complex and important topic when modeling
survival data. For more info, check out RMS Chapter 3 or van Burren's
FIMD (both referenced above). Because so few values are missing, we'll opt
for casewise completion for the rest of this tutorial.

```{r}
prostate <- prostate %>%
  drop_na()
```

## Model Fitting

With our data clean, we can move on to modeling. 
Cox Proportional Hazards (PH) regression is one of the
most popular forms of survival analysis because 
we can analyze many variables with assumptions
that are often reasonable for clinical practice.

The R packages `survival` and `rms` provide Cox
regression functionality. In `survival`, users
call `coxph()` while `cph()` is used in `rms`.
We'll focus on `cph()` because both work similarly
and `cph` adds some extra functionality. 

We're trying to evaluate how several variables,
including treatment `rx` affects survival. Cox
let's us analyze the impact of several variable
simultaneously by including any relevant
variables in the regression equation. 

We want to know if treatment improved
survival for prostate patients and how
age is related to survival.

Before we can start modeling, we need
to tell `rms` how the data is formatted.

```{r}
ddist <- datadist(prostate)
options(datadist="ddist")
```

Including treatment `rx` and age `age` in
our regression model will answer both
these questions.

```{r}
fit <- cph(Surv(dtime, status) ~ rx + age, data = prostate)
fit
```

`cph` uses the formula notation to specify regression models. In
formula notation, the response variable (usually denoted `Y`) is placed
on the left hand side of the `~` and explanatory variables go
on the right hand side (usually denoted `X`).

Our response variable `Y` is censored survival time outcomes,
represented by `Surv(dtime, status)`. `Surv` uses time to event (`dtime`)
and the outcome (`status`) to convert this info into a format
readable by `R`. On the right hand side we've included `rx` and
`age` as our explanatory variables. 

Printing `fit` shows the log(Hazard Ratio) and p-value for
each explanatory variable. `rx` shows up multiple times because
it is a factor with multiple levels. Each coefficent for `rx` is
for that dose compared against control. 

Age is treated as a continuous variable, with the assumption
that age is linearly related to survival. With our data,
this means that for every additional year patients will have
an added $e^{0.0322} = $ `r exp(0.0322)`

To visualize age's relation to survival, we plot
age vs hazard

```{r}
ggplot(Predict(fit, age)) +
  labs(x = "Age in Years") +
  ggtitle("Relationship between age and hazard")
```

Remember that a log hazard ratio > 0 means an increased risk of death. 
To plot hazard ratio instead, set `fun = exp` inside `Predict()`. The plot
shows that patients over the age of 70 have an increased risk of death from
prostate cancer. A naive reader might see this hazard ratio and the p-value for
age (p=.003) and conclude age causes patients to die. Careful! Although age
may be causally linked to death, this RCT wasn't designed to test age's causal
effect on survival, only its relation. Hazard ratios and p-values alone
can never determine causality for a variable; causality is determined
by the experimental design. Avoiding making causal statements just because
of small p-values!

### Relaxing the linearity assumption

Some continuous variables may not be linearly related to survival.
When we have sufficient sample size, it's optimal to treat
these variables as nonlinear. This will improve power
to detect a relationship and can improve effect estimation.

`rms` uses `rcs()` to model nonlinear variable with
restricted cubic splines. We can use splines to treat
age as if it's nonlinearly related to survival.

```{r}
nonlinear.fit <- cph(Surv(dtime, status) ~ rx + rcs(age,3), data = prostate)
nonlinear.fit
```

We must choose how many knots to use when modeling nonlinear
variables. The number of knots determines how closely the
regression fits the data. It's recommended to use 3 to 5 knots
for most problems: 3 for small datasets (~300 samples),
4 for medium datasets (~500 samples), and 5 for large datasets 
(~700 samples). Choosing the wrong number of knots can overfit
the model. We chose 3 knots due to our smaller sample size. 

Multiple parameters are needed to model a nonlinear variable
(`age` and `age'`). This makes interpretting our results more complicated.
Instead of just looking at the coefficient for `age`, we'll need to plot
age vs hazard. 

```{r}
ggplot(Predict(nonlinear.fit, age)) +
  labs(x = "Age in Years") +
  ggtitle("Relationship between age and hazard")
```

A one year increase in age no longer has a simple effect on survival.
It seems patients younger than 70 are all at a relatively equal
lower probability of death from prostate cancer. After about 70 years of age, patients
are at an increased risk. P-values are also not as straightforward to
interpret. Because age can have a non-monotonic relationship with
survival, we need a p-value to test if the nonlinear age function
is associated with survival. 

Using a chunk ANOVA test, we can compute p-values
testing whether each predictor is associated with survival.

```{r}
anova(nonlinear.fit)
```

Both `rx` and `age` have strong evidence
suggesting they're associated with survival.
The nonlinear p-value subsection under Age tests
whether there is evidence of a nonlinear relationship
between age and survival. If the p-value is large,
this may mean age is  linearly related to survival.
If this is true, don't remove the nonlinear age term from
the model - that violates p-value inference and will decrease
model performance. 

### Proper subgroup analysis using interactions

Precision medicine emphasizes treatment effect
heterogeneity: due to differing patient characteristics,
a drug that may work for one person won't necessarily
work for another. These concerns often drive researchers
to investigate subgroup differences. Subgroups can
be derived from any stratifying feature; male/female or mutation/no
mutation are common stratifying factors. 

To investigate subgroup differences, it's common for researchers
to divide patients into separate cohorts based on the stratifying
factor, perform a separate analysis for each cohort, and then
compare findings between cohorts. For a survival analysis, this
could be dividing patients into male and female cohorts,
fitting Cox regressions for each cohort, and then comparing
the hazard ratios and p-values between males and females. If any of
the hazard ratios or p-values differ, investigators will often claim 
effect heterogeneity between sexes. 

Unfortunately there are problems with this analysis. First,
splitting patients into separate cohorts reduces sample size,
making it more difficult to detect effects. This is especially
problematic when the subgroups are imbalanced. If there were 4x
more males than females, it will be easier to find a "significant"
hazard ratio for the males than the females because there are more
males. Finding a significant hazard ratio in one cohort but not
the other doesn't necessarily mean the effect sizes are differently;
a smaller sample size in the female cohort may be making the p-value
larger even though the underlying hazard ratios are the same.

Second, subgroup analysis doesn't provide any means to test or
estimate the effect difference between cohorts. Although males may have
a different hazard ratio than females, how can we be sure this difference
isn't due to sampling error? There also isn't an easy
way to build a confidence interval for the hazard ratio difference
betewen sexes. Without a p-value or confidence interval, it's hard
to be confident that the male/female difference we're observing
is truly real. 

To remedy these problems, we should be using interaction terms
in our regression formulas. An interaction term models how the hazard
ratio of one variable changes for different values of another variable.
An interaction term between treatment and mutation/no mutation could
be used to assess whether patients with the mutation experience a
better response. We can also compute p-values and confidence intervals
for interaction terms, helping us understand our uncertainty about
the effect heterogeneity. 

Interactions are easy to include in R formulas

```{r}
interact.fit <- cph(Surv(dtime, status) ~ rx*bm, data = prostate)
interact.fit
```

Above we've included an interaction term between treatment `rx` and 
bone metastasis `bm`,
useful if we suspect treatment efficacy differs between patients
with and without bone metastases. In R, `x1*x2` specifies an interaction
term between `x1` and `x2` and will also include `x1` and `x2` as separate
terms. Its equivalent to writing `x1 + x2 + x1*x2`. We can look the p-values
to weigh the evidence for treatment differences among bone metastases groups. 
0.2 mg and 1.0 mg of estrogen have large p-values, suggesting there may be no
difference in treatment effect between patients with/without bone metastasis.
Although this seems logical from the p-values, be cautious interpretting
interactions; most interactions are underpowered because sample
sizes are often halved (or worse) due to the nature of comparing two
separate groups. Interactions often require 16x the number of
patients to achieve the same power as normal variables, so unless
the analysis was powered for an interaction, interpret
these results careful. 

Meanwhile 5.0 mg estrogen's small p-value suggests evidence for
treatment effect heterogeneity. `bm` is an indicator variable
with a status of 0 (no metastasis) or 1 (bone metastasis). 
We interpret the interaction as follows: if `bm = 1`, the coefficient
would be -.8701, a rather large hazard reduction. If `bm = 0`,
the coefficient is 0, because $0 * -.8701 = 0$. It seems
patient's with bone metastases show a much better response
to 5.0 mg of estrogen than patients without bone metastases.

```{r}
ggplot(Predict(interact.fit, rx=c("5.0 mg estrogen"), bm))
```


`anova()` will also tell us the overall effect of the
interaction

```{r}
anova(interact.fit)
```

Make sure to check the overall interaction's p-value with
anova before looking at individual level p-values. If the overall
interaction isn't meaningfully small, the individual terms should be considered
weak evidence.  

A final note on interpretting interaction terms. If there is enough
evidence to believe the interaction term is non-null, to calculate
the final hazard ratio for each subgroup, we must add the two coefficients
together. For people with bone metastases given 5.0 mg of estrogen, we would
compute $


### Checking Model Assumptions


